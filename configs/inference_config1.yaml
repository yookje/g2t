train_data_path: tmp.pkl #/root/CycleFormer/tsp100_train_concorde_small.txt #tmp.txt #
val_data_path: tmp_val.pkl #/root/CycleFormer/tsp100_test_concorde.txt # # #tmp_val.txt #
node_size: 20 #100 #500 #500 #100
train_batch_size: 80 #40 # [tsp50, tsp100, tsp500, tsp1000]: 80
val_batch_size: 1280 #16 # [tsp50, tsp100]: 1280, [tsp500, tsp1000]: 128
test_batch_size: 1280 #1280 #6 #16
G: 1 #20 #100 #1
resume_checkpoint: #/root/FuzzyFormer/logs/lightning_logs/version_599/checkpoints/TSP20-epoch=00-opt_gap=115.3660.ckpt
gpus: [0] #, 1, 2, 3]
max_epochs: 1 #100 #100
enc_num_layers: 6 #6 #12
dec_num_layers: 6 #12
d_model: 128 #128 #256
d_ff: 1024
h: 8
dropout: 0.1
smoothing: 0.1
seed: 1
lr: 0.5
betas: [0.9, 0.98]
eps: 1e-9
factor: 1.0
warmup: 400
encoder_pe: 2D # None, 2D
decoder_pe: circular PE # None, 1D, circular 
decoder_lut: memory # shared, unshared, memory
comparison_matrix: memory # encoder_lut, decoder_lut, memory
use_start_token : False
